#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´ç»“æ„åŒ–åˆ†æåˆ†å±‚æ€»ç»“å·¥å…· - MongoDBé›†æˆç‰ˆ
"""

import os
import json
import time
import re
import uuid
import asyncio
from datetime import datetime
from pathlib import Path
import requests
from typing import Dict, Any, Optional, List

class NovelAnalyzer:
    """å°è¯´åˆ†å±‚ç»“æ„åŒ–åˆ†æå·¥å…· - æ”¯æŒMongoDBå­˜å‚¨"""
    
    def __init__(self, database):
        """åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            database: Databaseå®ä¾‹ï¼Œç”¨äºå­˜å‚¨åˆ†æç»“æœ
        """
        self.db = database
        self.model_config = {
            "base_url": "http://10.60.36.76:3100/v1",
            "api_key": "sk-d8rhT8SRFuXbTL5l304c83D58bA44488A2094807Da2cEcBe",
            "model_name": "gpt-5-chat",
            "timeout": 120,
            "max_retries": 3
        }
        
        # Step 1: ç« èŠ‚çº§æ€»ç»“æç¤ºè¯
        self.chapter_summary_prompt = """ä½ æ˜¯ä¸€ä¸ªå°è¯´å†…å®¹ç»“æ„åˆ†æä¸“å®¶ã€‚è¯·é˜…è¯»ä»¥ä¸‹å°è¯´å†…å®¹ç‰‡æ®µï¼Œæå–å¹¶æ€»ç»“ä»¥ä¸‹ä¿¡æ¯ï¼š

1. æ•…äº‹æƒ…èŠ‚æ¦‚è¦ï¼ˆ500-800å­—ï¼‰
2. ä¸»è¦äººç‰©ï¼ˆå«æ€§æ ¼ã€å…³ç³»ã€åŠ¨æœºï¼‰
3. å…³é”®äº‹ä»¶ä¸å†²çª
4. æƒ…ç»ªä¸æ°›å›´å˜åŒ–
5. èŠ‚å¥ä¸å™äº‹ç»“æ„
6. åœºæ™¯ç±»å‹ä¸å‘ˆç°æ€§ï¼ˆæ˜¯å¦å…·å¤‡å½±è§†åŒ–æ½œåŠ›ï¼‰
7. æ ‡ç­¾æå–ï¼ˆä¸»é¢˜ã€æƒ…æ„Ÿã€é¢˜æã€ä¸–ç•Œè§‚ã€æ—¶ä»£èƒŒæ™¯ã€å…ƒç´ ï¼‰
8. å…³é”®åè½¬æˆ–é«˜æ½®ç‚¹

è¯·è¾“å‡ºä¸ºJSONç»“æ„ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- segment_id: æ®µè½ID
- summary: æ•…äº‹æƒ…èŠ‚æ¦‚è¦
- main_characters: ä¸»è¦äººç‰©åˆ—è¡¨
- conflicts: å†²çªåˆ—è¡¨
- emotional_flow: æƒ…ç»ªæ°›å›´å˜åŒ–
- tags: æ ‡ç­¾åˆ—è¡¨
- plot_points: å…³é”®æƒ…èŠ‚ç‚¹
- analysis: åˆ†ææŒ‡æ ‡
- meta: å…ƒæ•°æ®
- content_refs: å†…å®¹å¼•ç”¨ï¼ˆç©ºæ•°ç»„ï¼‰

å°è¯´å†…å®¹ç‰‡æ®µï¼š
"""

        # Step 2: ä¸­å±‚æ±‡æ€»æç¤ºè¯
        self.group_summary_prompt = """ä½ æ˜¯ä¸€ä¸ªå°è¯´ç»“æ„ä¸å™äº‹åˆ†æä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯å°è¯´çš„å¤šä¸ªç‰‡æ®µæ€»ç»“ï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯æç‚¼æ›´é«˜å±‚æ¬¡çš„å™äº‹é€»è¾‘å’ŒæŒ‡æ ‡ï¼š

è¯·æ€»ç»“ï¼š
1. ä¸»çº¿æ•°é‡ä¸æ”¯çº¿ç‰¹å¾
2. å†²çªå¯†åº¦ï¼ˆæ¯ä¸‡å­—å†²çªæ•°ä¼°è®¡ï¼‰
3. é«˜æ½®ä¸åè½¬ç‚¹æ•°é‡ä¸åˆ†å¸ƒ
4. èŠ‚å¥å˜åŒ–è¶‹åŠ¿ï¼ˆå¹³ç¨³ / åŠ é€Ÿ / éœ‡è¡ï¼‰
5. ä¸»è¦äººç‰©æˆé•¿æˆ–å…³ç³»æ¼”å˜
6. æ•…äº‹å¼ åŠ›ä¸å™äº‹é©±åŠ¨åŠ›æ¥æº
7. åœºæ™¯ç±»å‹åˆ†å¸ƒï¼ˆå†…æ™¯/å¤–æ™¯ã€æˆ˜æ–—/æƒ…æ„Ÿ/å¯¹è¯ï¼‰
8. æ ‡ç­¾é›†ä¸­åº¦ï¼ˆæ ¸å¿ƒä¸»é¢˜æ˜¯å¦èšç„¦ï¼‰

è¯·è¾“å‡ºJSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- group_id: ç»„ID
- summary: è¯¥ç»„ç« èŠ‚çš„æ•´ä½“å™äº‹å‘å±•
- analysis: åˆ†ææŒ‡æ ‡
- meta: å…ƒæ•°æ®
- content_refs: å†…å®¹å¼•ç”¨

ç« èŠ‚ç‰‡æ®µæ€»ç»“æ•°æ®ï¼š
"""

        # Step 3: å…¨ä¹¦çº§æ•´åˆæç¤ºè¯
        self.book_summary_prompt = """ä½ æ˜¯ä¸€ä¸ªå°è¯´å…¨å±€å†…å®¹è¯„ä¼°ä¸“å®¶ã€‚è¯·ç»¼åˆæ‰€æœ‰ä¸­å±‚æ€»ç»“ä¿¡æ¯ï¼Œå®Œæˆå…¨ä¹¦åˆ†æï¼Œè¾“å‡ºå…¨é¢æŒ‡æ ‡ã€‚

è¯·ä»ä»¥ä¸‹è§’åº¦æç‚¼ï¼š
1. ä¸»çº¿æ•°é‡
2. å†²çªå¯†åº¦
3. é«˜æ½®/åè½¬ç‚¹æ•°é‡
4. èŠ‚å¥ç±»å‹ï¼ˆå¹³ç¨³/èµ·ä¼/å¿«èŠ‚å¥/æ…¢çƒ­ï¼‰
5. äººç‰©æ•°é‡ä¸ä¸»è§’é²œæ˜åº¦
6. äººç‰©å…³ç³»æƒ…ç»ªåº¦
7. åœºæ™¯å¯å‘ˆç°æ€§ï¼ˆå½±è§†åŒ–ç¨‹åº¦ï¼‰
8. åŠ¨ä½œ/äº‹ä»¶æ¯”ä¾‹
9. ç‰¹æ•ˆéœ€æ±‚
10. å‰§æƒ…å¼ åŠ›
11. æƒ…ç»ªå…±é¸£åº¦
12. æ€§åˆ«å€¾å‘
13. å¹´é¾„æ®µ
14. æ ‡ç­¾æ•°é‡ã€æ ¸å¿ƒæ ‡ç­¾ã€æ ‡ç­¾é›†ä¸­åº¦
15. å…´è¶£åŒ¹é…ï¼ˆå—ä¼—åå¥½ï¼‰
16. ä¸»è¦äººç‰©åˆ—è¡¨ï¼ˆæå–å…¨ä¹¦ä¸­çš„æ ¸å¿ƒäººç‰©ï¼‰
17. ä¸»é¢˜æ ‡ç­¾ï¼ˆæå–å…¨ä¹¦çš„æ ¸å¿ƒä¸»é¢˜å’Œæƒ…æ„Ÿæ ‡ç­¾ï¼‰

è¾“å‡ºä¸ºæ ‡å‡†åŒ–JSONï¼š

```json
{
  "book_summary": "å…¨ä¹¦è®²è¿°äº†...",
  "analysis": {
    "main_storylines": 3,
    "avg_conflict_density": 0.017,
    "total_climax_points": 21,
    "rhythm_pattern": "ä¸­å¿«èŠ‚å¥",
    "character_count": 15,
    "protagonist_clarity": "å¼º",
    "relationship_complexity": "å¤æ‚",
    "scene_adaptability": "é«˜",
    "action_event_ratio": "7:3",
    "special_effects_need": "ä¸­",
    "plot_tension": "å¼º",
    "emotional_resonance": "é«˜",
    "gender_orientation": "ç”·æ€§å‘",
    "target_age": "16-25",
    "tag_count": 8,
    "core_tags": ["ç„å¹»", "æˆé•¿", "å¤ä»‡"],
    "tag_concentration": "é›†ä¸­",
    "interest_matching": "é«˜",
    "main_characters": ["ä¸»è§’å¼ ä¸‰", "å¥³ä¸»è§’æå››", "åæ´¾ç‹äº”"],
    "themes": ["æˆé•¿", "å¤ä»‡", "å‹æƒ…", "çˆ±æƒ…"]
  },
  "meta": {
    "source_id": "uuid-BOOK",
    "parent_id": {parent_ids},
    "level": "book",
    "position": {"start_chapter": 1, "end_chapter": {total_chapters}},
    "word_count": {total_words},
    "genre": {all_genres},
    "version": "v1.0",
    "timestamp": "{timestamp}"
  },
  "content_refs": {content_refs}
}
```

ä¸­å±‚æ±‡æ€»æ•°æ®ï¼š
"""
    
    def read_novel(self, file_path: str) -> str:
        """è¯»å–å°è¯´æ–‡ä»¶"""
        encodings = ['gbk', 'gb2312', 'utf-8', 'utf-8-sig', 'latin1']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                print(f"æˆåŠŸè¯»å–æ–‡ä»¶: {file_path} (ç¼–ç : {encoding})")
                print(f"æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
                return content
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶å¤±è´¥ ({encoding}): {e}")
                continue
        
        print("æ‰€æœ‰ç¼–ç å°è¯•å‡å¤±è´¥")
        return ""
    
    def split_into_segments(self, content: str, segment_size: int = 50000) -> List[Dict[str, Any]]:
        """å°†å°è¯´å†…å®¹æŒ‰æ®µè½æ‹†åˆ†ï¼ˆæ¯æ®µçº¦5ä¸‡å­—ï¼‰"""
        print(f"æ­£åœ¨æŒ‰ {segment_size} å­—ç¬¦æ‹†åˆ†å°è¯´...")
        
        segments = []
        for i in range(0, len(content), segment_size):
            segment_content = content[i:i + segment_size]
            segments.append({
                'segment_number': len(segments) + 1,
                'content': segment_content,
                'start_pos': i,
                'end_pos': min(i + segment_size, len(content)),
                'word_count': len(segment_content)
            })
        
        print(f"å…±åˆ†å‰²ä¸º {len(segments)} ä¸ªæ®µè½")
        return segments
    
    async def call_llm(self, prompt: str, max_tokens: int = 6000) -> Optional[str]:
        """è°ƒç”¨å¤§æ¨¡å‹API - å¼‚æ­¥ç‰ˆæœ¬"""
        headers = {
            "Authorization": f"Bearer {self.model_config['api_key']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model_config["model_name"],
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": max_tokens
        }
        
        for attempt in range(self.model_config["max_retries"]):
            try:
                print(f"   ğŸ”„ è°ƒç”¨æ¨¡å‹ (å°è¯• {attempt + 1}/{self.model_config['max_retries']})...")
                
                # ä½¿ç”¨asyncioåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œrequests
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(
                    None,
                    lambda: requests.post(
                        f"{self.model_config['base_url']}/chat/completions",
                        headers=headers,
                        json=data,
                        timeout=self.model_config["timeout"]
                    )
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if 'choices' in result and len(result['choices']) > 0:
                        content = result['choices'][0]['message']['content']
                        print(f"   âœ… æ¨¡å‹è°ƒç”¨æˆåŠŸ! (å“åº”é•¿åº¦: {len(content)} å­—ç¬¦)")
                        return content
                    else:
                        print(f"   âŒ æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯: {result}")
                else:
                    print(f"   âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                    
            except requests.exceptions.Timeout:
                print(f"   â° è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.model_config['max_retries']})")
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¤±è´¥: {e}")
            
            if attempt < self.model_config["max_retries"] - 1:
                wait_time = (attempt + 1) * 3
                print(f"   â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)
        
        print("   âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
        return None
    
    def clean_data_for_serialization(self, data):
        """æ¸…ç†æ•°æ®ï¼Œç¡®ä¿å¯ä»¥åºåˆ—åŒ–ä¸ºJSON"""
        if isinstance(data, dict):
            return {key: self.clean_data_for_serialization(value) for key, value in data.items()}
        elif isinstance(data, list):
            return [self.clean_data_for_serialization(item) for item in data]
        elif hasattr(data, '__str__') and not isinstance(data, (str, int, float, bool, type(None))):
            return str(data)
        else:
            return data
    
    def extract_json_from_response(self, response: str) -> Optional[Dict]:
        """ä»æ¨¡å‹å“åº”ä¸­æå–JSON"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            result = json.loads(response)
            return self.clean_data_for_serialization(result)
        except:
            # å°è¯•æå–```json```å—ä¸­çš„å†…å®¹
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group(1))
                    return self.clean_data_for_serialization(result)
                except:
                    pass
            
            # å°è¯•æå–{}å—
            brace_match = re.search(r'\{.*\}', response, re.DOTALL)
            if brace_match:
                try:
                    result = json.loads(brace_match.group(0))
                    return self.clean_data_for_serialization(result)
                except:
                    pass
            
            print("æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆJSON")
            return None
    
    async def step1_chapter_analysis(self, novel_id: str, segments: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Step 1: ç« èŠ‚çº§æ€»ç»“å¹¶ä¿å­˜åˆ°MongoDB"""
        print(f"\nğŸ“„ å¼€å§‹ç« èŠ‚çº§åˆ†æ ({len(segments)} ä¸ªæ®µè½)")
        print(f"{'â”€'*50}")
        
        chapter_results = []
        total_segments = len(segments)
        
        for i, segment in enumerate(segments):
            # æ›´æ–°è¯¦ç»†è¿›åº¦
            progress = 30 + int((i / total_segments) * 20)  # 30-50%
            self.update_progress(novel_id, progress, f"åˆ†æç« èŠ‚ {i+1}/{total_segments}", 
                               f"æ­£åœ¨åˆ†æç¬¬{i+1}ä¸ªæ®µè½ï¼Œå­—æ•°: {segment['word_count']:,}")
            
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {i + 1}/{len(segments)} ä¸ªæ®µè½...")
            print(f"   ğŸ“Š æ®µè½å­—æ•°: {segment['word_count']:,} å­—ç¬¦")
            print(f"   ğŸ“ ä½ç½®: {segment['start_pos']:,} - {segment['end_pos']:,}")
            
            # æ„å»ºæç¤ºè¯
            prompt = self.chapter_summary_prompt + f"""

æ®µè½ä¿¡æ¯ï¼š
- æ®µè½ç¼–å·: S{i+1:03d}
- å­—æ•°: {segment['word_count']}
- æ—¶é—´æˆ³: {datetime.now().isoformat()}

{segment['content']}"""
            
            # è°ƒç”¨æ¨¡å‹
            print(f"   ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹API...")
            self.update_progress(novel_id, progress, f"è°ƒç”¨AIåˆ†æç« èŠ‚ {i+1}", 
                               f"æ­£åœ¨è°ƒç”¨AIåˆ†æç¬¬{i+1}ä¸ªæ®µè½...")
            
            response = await self.call_llm(prompt, max_tokens=4000)
            if response:
                print(f"   ğŸ“ è§£ææ¨¡å‹å“åº”...")
                self.update_progress(novel_id, progress, f"è§£æAIå“åº” {i+1}", 
                                   f"æ­£åœ¨è§£æAIå¯¹ç¬¬{i+1}ä¸ªæ®µè½çš„åˆ†æç»“æœ...")
                
                result = self.extract_json_from_response(response)
                if result:
                    # æ·»åŠ å®é™…çš„UUIDå’Œå°è¯´ID
                    if 'meta' not in result:
                        result['meta'] = {}
                    
                    result['meta']['source_id'] = f"uuid-S{i+1:03d}-{str(uuid.uuid4())[:8]}"
                    result['segment_id'] = f"S{i+1:03d}"
                    result['novel_id'] = novel_id
                    result['segment_number'] = i + 1
                    
                    # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                    if 'meta' in result and isinstance(result['meta'], dict):
                        for key, value in result['meta'].items():
                            if hasattr(value, '__str__'):
                                result['meta'][key] = str(value)
                    
                    chapter_results.append(result)
                    print(f"   âœ… æ®µè½ {i + 1} åˆ†æå®Œæˆ")
                    self.update_progress(novel_id, progress, f"ç« èŠ‚ {i+1} åˆ†æå®Œæˆ", 
                                       f"ç¬¬{i+1}ä¸ªæ®µè½åˆ†æå®Œæˆï¼Œå·²åˆ†æ {len(chapter_results)} ä¸ªæ®µè½")
                else:
                    print(f"   âŒ æ®µè½ {i + 1} JSONè§£æå¤±è´¥")
                    self.update_progress(novel_id, progress, f"ç« èŠ‚ {i+1} è§£æå¤±è´¥", 
                                       f"ç¬¬{i+1}ä¸ªæ®µè½çš„AIå“åº”è§£æå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")
            else:
                print(f"   âŒ æ®µè½ {i + 1} æ¨¡å‹è°ƒç”¨å¤±è´¥")
                self.update_progress(novel_id, progress, f"ç« èŠ‚ {i+1} è°ƒç”¨å¤±è´¥", 
                                   f"ç¬¬{i+1}ä¸ªæ®µè½çš„AIè°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")
            
            # æ·»åŠ å»¶è¿Ÿ
            if i < len(segments) - 1:
                print(f"   â³ ç­‰å¾… 3 ç§’åç»§ç»­...")
                self.update_progress(novel_id, progress, f"ç­‰å¾…å¤„ç†ä¸‹ä¸€ç« èŠ‚", 
                                   f"ç¬¬{i+1}ä¸ªæ®µè½å¤„ç†å®Œæˆï¼Œç­‰å¾…3ç§’åå¤„ç†ç¬¬{i+2}ä¸ªæ®µè½...")
                await asyncio.sleep(3)
        
        # ä¿å­˜åˆ°MongoDB
        if chapter_results:
            print(f"\n[SAVE] ä¿å­˜ç« èŠ‚åˆ†æç»“æœåˆ°æ•°æ®åº“...", flush=True)
            # æ¸…ç†æ•°æ®ç¡®ä¿å¯åºåˆ—åŒ–
            cleaned_results = [self.clean_data_for_serialization(result) for result in chapter_results]
            await self.db.save_chapter_analysis(novel_id, cleaned_results)
            print(f"[SUCCESS] ç« èŠ‚çº§åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æå¹¶ä¿å­˜ {len(chapter_results)} ä¸ªæ®µè½", flush=True)
        else:
            print(f"[WARNING] æ²¡æœ‰ç« èŠ‚åˆ†æç»“æœéœ€è¦ä¿å­˜", flush=True)
        
        return chapter_results
    
    async def step2_group_analysis(self, novel_id: str, chapter_results: List[Dict[str, Any]], group_size: int = 10) -> List[Dict[str, Any]]:
        """Step 2: ä¸­å±‚æ±‡æ€»æ€»ç»“å¹¶ä¿å­˜åˆ°MongoDB"""
        print(f"\nğŸ“‘ å¼€å§‹ä¸­å±‚æ±‡æ€»åˆ†æ (æ¯ç»„ {group_size} ä¸ªæ®µè½)")
        print(f"{'â”€'*50}")
        
        # åˆ†ç»„
        groups = []
        for i in range(0, len(chapter_results), group_size):
            group = chapter_results[i:i + group_size]
            groups.append(group)
        
        print(f"ğŸ“Š ç« èŠ‚å·²åˆ†ä¸º {len(groups)} ç»„è¿›è¡Œæ±‡æ€»")
        
        group_results = []
        total_groups = len(groups)
        
        for i, group in enumerate(groups):
            # æ›´æ–°è¯¦ç»†è¿›åº¦
            progress = 60 + int((i / total_groups) * 15)  # 60-75%
            self.update_progress(novel_id, progress, f"æ±‡æ€»ç»„ {i+1}/{total_groups}", 
                               f"æ­£åœ¨æ±‡æ€»ç¬¬{i+1}ç»„ï¼ŒåŒ…å«{len(group)}ä¸ªæ®µè½")
            
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {i + 1}/{len(groups)} ç»„...")
            print(f"   ğŸ“Š ç»„å†…æ®µè½æ•°: {len(group)} ä¸ª")
            print(f"   ğŸ“ æ®µè½èŒƒå›´: {group[0].get('segment_number', 1)} - {group[-1].get('segment_number', len(group))}")
            
            # å‡†å¤‡content_refs
            content_refs = []
            parent_ids = []
            total_word_count = 0
            all_genres = set()
            
            for chapter in group:
                content_refs.append({
                    "segment_id": chapter.get('segment_id'),
                    "summary": chapter.get('summary'),
                    "analysis": chapter.get('analysis')
                })
                
                # å®‰å…¨åœ°è·å–metaä¿¡æ¯
                meta = chapter.get('meta', {})
                parent_ids.append(meta.get('source_id', f'unknown-{len(parent_ids)}'))
                
                # å®‰å…¨åœ°è·å–å­—æ•°ï¼Œç¡®ä¿æ˜¯æ•°å­—
                word_count = meta.get('word_count', 0)
                if isinstance(word_count, str):
                    try:
                        word_count = int(word_count)
                    except (ValueError, TypeError):
                        word_count = 0
                elif not isinstance(word_count, (int, float)):
                    word_count = 0
                total_word_count += word_count
                
                # å®‰å…¨åœ°è·å–genreä¿¡æ¯
                genre = meta.get('genre', [])
                if isinstance(genre, list):
                    all_genres.update(genre)
                elif isinstance(genre, str):
                    all_genres.add(genre)
            
            # æ„å»ºæç¤ºè¯
            group_data = json.dumps(group, ensure_ascii=False, indent=2)
            prompt = self.group_summary_prompt + f"""

ç»„ä¿¡æ¯ï¼š
- ç»„ç¼–å·: G{i+1:03d}
- çˆ¶èŠ‚ç‚¹ID: {parent_ids}
- ç« èŠ‚èŒƒå›´: {group[0].get('segment_number', 1)}-{group[-1].get('segment_number', len(group))}
- æ€»å­—æ•°: {total_word_count}
- ç±»å‹: {list(all_genres)}
- æ—¶é—´æˆ³: {datetime.now().isoformat()}

ç« èŠ‚æ•°æ®ï¼š
{group_data}"""
            
            # è°ƒç”¨æ¨¡å‹
            print(f"   ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹APIè¿›è¡Œæ±‡æ€»...")
            self.update_progress(novel_id, progress, f"è°ƒç”¨AIæ±‡æ€»ç»„ {i+1}", 
                               f"æ­£åœ¨è°ƒç”¨AIæ±‡æ€»ç¬¬{i+1}ç»„ï¼ŒåŒ…å«{len(group)}ä¸ªæ®µè½...")
            
            response = await self.call_llm(prompt, max_tokens=5000)
            if response:
                print(f"   ğŸ“ è§£ææ¨¡å‹å“åº”...")
                self.update_progress(novel_id, progress, f"è§£æAIæ±‡æ€»å“åº” {i+1}", 
                                   f"æ­£åœ¨è§£æAIå¯¹ç¬¬{i+1}ç»„çš„æ±‡æ€»ç»“æœ...")
                result = self.extract_json_from_response(response)
                if result:
                    # æ·»åŠ å®é™…çš„UUIDå’Œå°è¯´ID
                    if 'meta' not in result:
                        result['meta'] = {}
                    
                    result['meta']['source_id'] = f"uuid-G{i+1:03d}-{str(uuid.uuid4())[:8]}"
                    result['group_id'] = f"G{i+1:03d}"
                    result['novel_id'] = novel_id
                    result['group_number'] = i + 1
                    result['content_refs'] = content_refs
                    
                    group_results.append(result)
                    print(f"   âœ… ç»„ {i + 1} æ±‡æ€»å®Œæˆ")
                else:
                    print(f"   âŒ ç»„ {i + 1} JSONè§£æå¤±è´¥")
            else:
                print(f"   âŒ ç»„ {i + 1} æ¨¡å‹è°ƒç”¨å¤±è´¥")
            
            # æ·»åŠ å»¶è¿Ÿ
            if i < len(groups) - 1:
                print(f"   â³ ç­‰å¾… 5 ç§’åç»§ç»­...")
                await asyncio.sleep(5)
        
        # ä¿å­˜åˆ°MongoDB
        if group_results:
            print(f"\n[SAVE] ä¿å­˜ä¸­å±‚æ±‡æ€»ç»“æœåˆ°æ•°æ®åº“...", flush=True)
            # æ¸…ç†æ•°æ®ç¡®ä¿å¯åºåˆ—åŒ–
            cleaned_results = [self.clean_data_for_serialization(result) for result in group_results]
            await self.db.save_group_analysis(novel_id, cleaned_results)
            print(f"[SUCCESS] ä¸­å±‚æ±‡æ€»å®Œæˆï¼ŒæˆåŠŸæ±‡æ€»å¹¶ä¿å­˜ {len(group_results)} ç»„", flush=True)
        else:
            print(f"[WARNING] æ²¡æœ‰ä¸­å±‚æ±‡æ€»ç»“æœéœ€è¦ä¿å­˜", flush=True)
        
        return group_results
    
    async def step3_book_analysis(self, novel_id: str, group_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Step 3: å…¨ä¹¦çº§æ•´åˆæ€»ç»“å¹¶ä¿å­˜åˆ°MongoDB"""
        print(f"\nğŸ“š å¼€å§‹å…¨ä¹¦çº§æ•´åˆåˆ†æ")
        print(f"{'â”€'*50}")
        print(f"ğŸ“Š åŸºäº {len(group_results)} ä¸ªä¸­å±‚æ±‡æ€»ç»“æœè¿›è¡Œå…¨ä¹¦åˆ†æ")
        
        # æ›´æ–°è¿›åº¦
        self.update_progress(novel_id, 85, "å¼€å§‹å…¨ä¹¦åˆ†æ", 
                           f"æ­£åœ¨æ•´åˆ{len(group_results)}ä¸ªä¸­å±‚æ±‡æ€»ç»“æœè¿›è¡Œå…¨ä¹¦åˆ†æ...")
        
        # å‡†å¤‡content_refs
        content_refs = []
        parent_ids = []
        total_word_count = 0
        all_genres = set()
        total_chapters = 0
        
        for group in group_results:
            content_refs.append({
                "group_id": group.get('group_id'),
                "summary": group.get('summary'),
                "analysis": group.get('analysis'),
                "content_refs": group.get('content_refs', [])
            })
            
            # å®‰å…¨åœ°è·å–metaä¿¡æ¯
            meta = group.get('meta', {})
            parent_ids.append(meta.get('source_id', f'unknown-group-{len(parent_ids)}'))
            
            # å®‰å…¨åœ°è·å–å­—æ•°ï¼Œç¡®ä¿æ˜¯æ•°å­—
            word_count = meta.get('word_count', 0)
            if isinstance(word_count, str):
                try:
                    word_count = int(word_count)
                except (ValueError, TypeError):
                    word_count = 0
            elif not isinstance(word_count, (int, float)):
                word_count = 0
            total_word_count += word_count
            
            # å®‰å…¨åœ°è·å–genreä¿¡æ¯
            genre = meta.get('genre', [])
            if isinstance(genre, list):
                all_genres.update(genre)
            elif isinstance(genre, str):
                all_genres.add(genre)
            
            # è·å–ç« èŠ‚æ•°é‡
            group_number = group.get('group_number', 0)
            if isinstance(group_number, str):
                try:
                    group_number = int(group_number)
                except (ValueError, TypeError):
                    group_number = 0
            elif not isinstance(group_number, (int, float)):
                group_number = 0
            total_chapters = max(total_chapters, group_number)
        
        # æ„å»ºæç¤ºè¯
        group_data = json.dumps(group_results, ensure_ascii=False, indent=2)
        prompt = self.book_summary_prompt + f"""

å…¨ä¹¦ä¿¡æ¯ï¼š
- çˆ¶èŠ‚ç‚¹ID: {parent_ids}
- æ€»ç« èŠ‚æ•°: {total_chapters}
- æ€»å­—æ•°: {total_word_count}
- æ‰€æœ‰ç±»å‹: {list(all_genres)}
- æ—¶é—´æˆ³: {datetime.now().isoformat()}

ç»„æ±‡æ€»æ•°æ®ï¼š
{group_data}"""
        
        # è°ƒç”¨æ¨¡å‹
        print(f"ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹APIè¿›è¡Œå…¨ä¹¦åˆ†æ...")
        self.update_progress(novel_id, 90, "è°ƒç”¨AIå…¨ä¹¦åˆ†æ", 
                           f"æ­£åœ¨è°ƒç”¨AIè¿›è¡Œå…¨ä¹¦çº§æ•´åˆåˆ†æï¼ŒåŸºäº{len(group_results)}ä¸ªä¸­å±‚æ±‡æ€»...")
        
        response = await self.call_llm(prompt, max_tokens=6000)
        if response:
            print(f"ğŸ“ è§£ææ¨¡å‹å“åº”...")
            self.update_progress(novel_id, 95, "è§£æAIå…¨ä¹¦å“åº”", 
                               f"æ­£åœ¨è§£æAIçš„å…¨ä¹¦çº§åˆ†æç»“æœ...")
            result = self.extract_json_from_response(response)
            if result:
                # æ·»åŠ å®é™…çš„UUIDå’Œå°è¯´ID
                if 'meta' not in result:
                    result['meta'] = {}
                
                result['meta']['source_id'] = f"uuid-BOOK-{str(uuid.uuid4())[:8]}"
                result['novel_id'] = novel_id
                result['content_refs'] = content_refs
                
                # ä¿å­˜åˆ°MongoDB
                print(f"[SAVE] ä¿å­˜å…¨ä¹¦åˆ†æç»“æœåˆ°æ•°æ®åº“...", flush=True)
                # æ¸…ç†æ•°æ®ç¡®ä¿å¯åºåˆ—åŒ–
                cleaned_result = self.clean_data_for_serialization(result)
                await self.db.save_book_analysis(novel_id, cleaned_result)
                print("[SUCCESS] å…¨ä¹¦åˆ†æå®Œæˆå¹¶å·²ä¿å­˜", flush=True)
                return result
            else:
                print("[ERROR] å…¨ä¹¦åˆ†æJSONè§£æå¤±è´¥", flush=True)
        else:
            print("[ERROR] å…¨ä¹¦åˆ†ææ¨¡å‹è°ƒç”¨å¤±è´¥", flush=True)
        
        return None
    
    def update_progress(self, novel_id: str, progress: int, step: str, message: str = ""):
        """æ›´æ–°åˆ†æè¿›åº¦"""
        try:
            from main import analysis_progress
            analysis_progress[novel_id] = {
                "status": "processing",
                "progress": progress,
                "current_step": step,
                "message": message,
                "timestamp": datetime.now().isoformat()
            }
            print(f"[PROGRESS] {novel_id}: {progress}% - {step} - {message}", flush=True)
        except Exception as e:
            print(f"[PROGRESS ERROR] æ›´æ–°è¿›åº¦å¤±è´¥: {e}", flush=True)

    async def analyze_novel_async(self, novel_id: str, file_path: str):
        """å¼‚æ­¥åˆ†æå°è¯´çš„å®Œæ•´æµç¨‹"""
        try:
            print(f"\n{'='*60}", flush=True)
            print(f"[TASK] åå°ä»»åŠ¡å¯åŠ¨: åˆ†æå°è¯´", flush=True)
            print(f"[ID] å°è¯´ID: {novel_id}", flush=True)
            print(f"[FILE] æ–‡ä»¶è·¯å¾„: {file_path}", flush=True)
            print(f"[TIME] å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
            print(f"[DB] æ•°æ®åº“çŠ¶æ€: {'å·²è¿æ¥' if self.db.client is not None else 'æœªè¿æ¥'}", flush=True)
            print(f"{'='*60}", flush=True)
            
            # åˆå§‹åŒ–è¿›åº¦
            self.update_progress(novel_id, 0, "åˆå§‹åŒ–", "å¼€å§‹åˆ†æå°è¯´")
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            await self.db.update_novel_status(novel_id, "processing")
            print("[STATUS] å°è¯´çŠ¶æ€å·²æ›´æ–°ä¸º: processing", flush=True)
            
            # è¯»å–å°è¯´å†…å®¹
            print("\n[STEP1] è¯»å–å°è¯´æ–‡ä»¶...", flush=True)
            self.update_progress(novel_id, 10, "è¯»å–æ–‡ä»¶", "æ­£åœ¨è¯»å–å°è¯´æ–‡ä»¶...")
            novel_content = self.read_novel(file_path)
            if not novel_content:
                await self.db.update_novel_status(novel_id, "failed")
                self.update_progress(novel_id, 0, "å¤±è´¥", "æ— æ³•è¯»å–å°è¯´å†…å®¹")
                print("[ERROR] æ— æ³•è¯»å–å°è¯´å†…å®¹", flush=True)
                return
            print(f"[SUCCESS] å°è¯´å†…å®¹è¯»å–æˆåŠŸï¼Œæ€»å­—æ•°: {len(novel_content):,} å­—ç¬¦", flush=True)
            self.update_progress(novel_id, 20, "æ–‡ä»¶è¯»å–å®Œæˆ", f"æˆåŠŸè¯»å– {len(novel_content):,} å­—ç¬¦")
            
            # Step 1: æ‹†åˆ†å¹¶åˆ†æç« èŠ‚
            print("\n[STEP2] ç« èŠ‚çº§åˆ†æ...", flush=True)
            self.update_progress(novel_id, 25, "æ‹†åˆ†ç« èŠ‚", "æ­£åœ¨æ‹†åˆ†å°è¯´ä¸ºç« èŠ‚...")
            segments = self.split_into_segments(novel_content, segment_size=50000)
            print(f"[INFO] å°è¯´å·²æ‹†åˆ†ä¸º {len(segments)} ä¸ªæ®µè½ï¼Œæ¯æ®µçº¦5ä¸‡å­—", flush=True)
            
            self.update_progress(novel_id, 30, "åˆ†æç« èŠ‚", f"å¼€å§‹åˆ†æ {len(segments)} ä¸ªç« èŠ‚...")
            chapter_results = await self.step1_chapter_analysis(novel_id, segments)
            
            if not chapter_results:
                await self.db.update_novel_status(novel_id, "failed")
                self.update_progress(novel_id, 0, "å¤±è´¥", "ç« èŠ‚çº§åˆ†æå¤±è´¥")
                print("[ERROR] ç« èŠ‚çº§åˆ†æå¤±è´¥", flush=True)
                return
            print(f"[SUCCESS] ç« èŠ‚çº§åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(chapter_results)} ä¸ªæ®µè½", flush=True)
            self.update_progress(novel_id, 50, "ç« èŠ‚åˆ†æå®Œæˆ", f"æˆåŠŸåˆ†æ {len(chapter_results)} ä¸ªç« èŠ‚")
            
            # Step 2: ä¸­å±‚æ±‡æ€»
            print("\n[STEP3] ä¸­å±‚æ±‡æ€»åˆ†æ...", flush=True)
            self.update_progress(novel_id, 60, "ä¸­å±‚æ±‡æ€»", "æ­£åœ¨è¿›è¡Œä¸­å±‚æ±‡æ€»åˆ†æ...")
            group_results = await self.step2_group_analysis(novel_id, chapter_results, group_size=10)
            
            if not group_results:
                await self.db.update_novel_status(novel_id, "failed")
                self.update_progress(novel_id, 0, "å¤±è´¥", "ä¸­å±‚æ±‡æ€»å¤±è´¥")
                print("[ERROR] ä¸­å±‚æ±‡æ€»å¤±è´¥", flush=True)
                return
            print(f"[SUCCESS] ä¸­å±‚æ±‡æ€»å®Œæˆï¼Œå…±æ±‡æ€» {len(group_results)} ç»„", flush=True)
            self.update_progress(novel_id, 75, "ä¸­å±‚æ±‡æ€»å®Œæˆ", f"æˆåŠŸæ±‡æ€» {len(group_results)} ç»„")
            
            # Step 3: å…¨ä¹¦æ•´åˆ
            print("\n[STEP4] å…¨ä¹¦çº§æ•´åˆåˆ†æ...", flush=True)
            self.update_progress(novel_id, 85, "å…¨ä¹¦åˆ†æ", "æ­£åœ¨è¿›è¡Œå…¨ä¹¦çº§æ•´åˆåˆ†æ...")
            book_result = await self.step3_book_analysis(novel_id, group_results)
            
            if not book_result:
                await self.db.update_novel_status(novel_id, "failed")
                self.update_progress(novel_id, 0, "å¤±è´¥", "å…¨ä¹¦åˆ†æå¤±è´¥")
                print("[ERROR] å…¨ä¹¦åˆ†æå¤±è´¥", flush=True)
                return
            print("[SUCCESS] å…¨ä¹¦çº§åˆ†æå®Œæˆ", flush=True)
            
            # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            await self.db.update_novel_status(novel_id, "completed")
            self.update_progress(novel_id, 100, "åˆ†æå®Œæˆ", "å°è¯´åˆ†æå…¨éƒ¨å®Œæˆï¼")
            
            print(f"\n{'='*60}", flush=True)
            print(f"[COMPLETE] å°è¯´åˆ†æå®Œæˆ!", flush=True)
            print(f"[ID] å°è¯´ID: {novel_id}", flush=True)
            print(f"[TIME] å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
            print(f"[STATS] åˆ†æç»Ÿè®¡:", flush=True)
            print(f"   - ç« èŠ‚æ®µè½: {len(chapter_results)} ä¸ª", flush=True)
            print(f"   - ä¸­å±‚ç»„æ•°: {len(group_results)} ç»„", flush=True)
            print(f"   - å…¨ä¹¦åˆ†æ: 1 ä¸ª", flush=True)
            print(f"{'='*60}", flush=True)
            
        except Exception as e:
            print(f"\n[ERROR] åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", flush=True)
            print(f"[ID] å°è¯´ID: {novel_id}", flush=True)
            print(f"[TIME] é”™è¯¯æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
            await self.db.update_novel_status(novel_id, "failed")
            print("[STATUS] å°è¯´çŠ¶æ€å·²æ›´æ–°ä¸º: failed", flush=True)
    
    def analyze_novel_sync(self, novel_id: str, file_path: str):
        """åŒæ­¥ç‰ˆæœ¬çš„å°è¯´åˆ†æï¼ˆç”¨äºç›´æ¥è°ƒç”¨ï¼‰"""
        return asyncio.run(self.analyze_novel_async(novel_id, file_path))
